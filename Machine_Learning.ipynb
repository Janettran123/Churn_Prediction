{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wrn_jGrwTXCY"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost\n",
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "rBCxqtB5Tb1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "vqaWx4OxTd1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all = pd.read_csv(\"ALL.csv\")"
      ],
      "metadata": {
        "id": "UhhAiws_Tct8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this analysis, we only want to look at customer churn for 2023 Quarter 1"
      ],
      "metadata": {
        "id": "VvUdHErRTfrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_two = all[all['quarter'].isin([1, 2])]"
      ],
      "metadata": {
        "id": "LkcU-2l-Te9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are getting all of the unique customer IDS from quarter 1 and 2 to\n",
        "# compare who churned vs whos still active\n",
        "\n",
        "quarter_1_df = all[all['quarter'] == 1]\n",
        "\n",
        "# Get all unique ids from the filtered DataFrame\n",
        "unique_1= quarter_1_df[['extid']].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "quarter_2_df = all[all['quarter'] == 2]\n",
        "\n",
        "# Get all unique ids from the filtered DataFrame\n",
        "unique_2= quarter_2_df[['extid']].drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "p3Bp27tuTnDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quarter_1_df = pd.merge(quarter_1_df, unique_1, on=['extid'], how= 'left')"
      ],
      "metadata": {
        "id": "YIG_aP4QTwTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_1['churn'] = unique_1['extid'].apply(lambda x: 0 if x in unique_2['extid'].values else 1)"
      ],
      "metadata": {
        "id": "P-TFqIOPTxyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quarter_1_df.to_csv(\"quarter1_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "TU20oTYqT6i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_two = pd.read_csv(\"quarter1_2.csv\")"
      ],
      "metadata": {
        "id": "5c5NpWHlT1ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking to see how many \"0\" we have which indicate no activity not missing activity\n",
        "zero_counts = (one_two == 0).sum()\n",
        "percentage_zero_counts = zero_counts / 55829 * 100\n",
        "percentage_zero_counts"
      ],
      "metadata": {
        "id": "Ltax39gnT-Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping extid and quarter for correlation matrix\n",
        "quarter_1_df.drop(columns=['extid','quarter'], inplace=True)"
      ],
      "metadata": {
        "id": "jAHzR1yPUI-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install packages\n",
        "# Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Evaluation Metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_curve, auc, accuracy_score\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n"
      ],
      "metadata": {
        "id": "LvI_beRiUQgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for nan\n",
        "nan_rows_all = one_two[one_two.isna().any(axis=1)]\n",
        "nan_rows_all"
      ],
      "metadata": {
        "id": "oR8rdCKIUUMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "corr = one_two.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(13,8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='viridis', linewidths=.5)\n",
        "plt.title('Heatmap of Attribute Correlation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x_WejGQ4UXOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out any high correlations\n",
        "high_corr_pairs = []\n",
        "for i in range(len(corr.columns)):\n",
        "    for j in range(i+1, len(corr.columns)):\n",
        "        if corr.iloc[i, j] > 0.8:\n",
        "            high_corr_pairs.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
        "\n",
        "print(\"Pairs of variables with correlation greater than 0.8:\")\n",
        "for pair in high_corr_pairs:\n",
        "    print(f\"{pair[0]} and {pair[1]} with correlation {pair[2]:.2f}\")"
      ],
      "metadata": {
        "id": "y52L0PyoUYHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check distribution of our y variable, 0 and 1 counts\n",
        "churn_count = one_two['churn'].value_counts()\n",
        "churn_count\n",
        "\n",
        "# here we have an imbalance, not churned (0) - 39529 while churned (1) - 16300"
      ],
      "metadata": {
        "id": "4E5tIVBrUb66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we need to balance our dataset in terms of our y variable, here we want a 50/50 split\n",
        "# so we're going to match the number of not churn (0) with churn (1)\n",
        "# churn has 16300 so we're going to randomly sample 16300 rows of not churned\n",
        "\n",
        "selected_rows_churn_0 = one_two[one_two['churn'] == 0].sample(n=16300, random_state=42)\n",
        "\n",
        "# Filter rows where churn is 1\n",
        "rows_churn_1 = one_two[one_two['churn'] == 1]\n",
        "\n",
        "# Concatenate selected_rows_churn_0 with rows_churn_1\n",
        "new_quarter = pd.concat([selected_rows_churn_0, rows_churn_1], ignore_index=True)\n",
        "\n",
        "churn_count = new_quarter['churn'].value_counts()\n",
        "churn_count"
      ],
      "metadata": {
        "id": "bcGHbIq9VQG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are going to prpare our datasets for training/testing\n",
        "\n",
        "X = new_quarter.drop('churn', axis=1)\n",
        "y = new_quarter['churn']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EExly-SRVsc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Accuarcy for some Baby models\n",
        "\n",
        "classifiers = [\n",
        "\n",
        "['DecisionTree :', DecisionTreeClassifier(max_depth=5)],\n",
        "['Naive Bayes :', GaussianNB()],\n",
        "['KNeighbours :', KNeighborsClassifier()]]\n",
        "\n",
        "# creating a classifier using each of the algorithms and prediciting their accuracies\n",
        "print('Accuracies:')\n",
        "for name, classifier in classifiers:\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    print(name, accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "cfswJu60VyRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HERE WE ARE GOING TO RUN AN ALL-IN LOGISTIC REGRESSION\n",
        "\n",
        "# Initialize a Logistic Regression classifier\n",
        "logreg_classifier = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(logreg_classifier, X_train, y_train, cv=10)\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lr = logreg_classifier.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "classification_report_result = classification_report(y_test, y_pred_lr)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Logistic Regression Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Logistic Regression Cross-Validation Scores Average:\", np.mean(cv_scores))\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report_result)\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\\n\", confusion_matrix_result)\n",
        "\n",
        "# THIS ALL IN LOGISITIC REGRESSION HAS AN ACCURACY OF 73%"
      ],
      "metadata": {
        "id": "aBpebYB5VzeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to check for variance\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Assuming X_train is a DataFrame excluding the target variable\n",
        "X = sm.add_constant(X_train)  # Adding a constant for intercept\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "JSRxctG0V2Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to display variables and their significance\n",
        "logit_model = sm.Logit(y_train, X_train)\n",
        "\n",
        "# Fit the model\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Print out the summary of the model\n",
        "print(result.summary())\n"
      ],
      "metadata": {
        "id": "PvYIrpJQV6ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# because this is a logisitic regression, we are now calculating the\n",
        "# probabilities so we can better interpret the results\n",
        "\n",
        "# Extract coefficients\n",
        "coefficients = result.params\n",
        "odds_ratios = np.exp(coefficients)\n",
        "\n",
        "# Create a DataFrame for easy interpretation\n",
        "interpretation_df = pd.DataFrame({\n",
        "    'Feature': coefficients.index,\n",
        "    'Coefficient (Log Odds)': coefficients.values,\n",
        "    'Odds Ratio': odds_ratios\n",
        "})\n",
        "\n",
        "print(interpretation_df)"
      ],
      "metadata": {
        "id": "t5DNyiosWE-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to run random forest to help with feature selection since our main dataset has 52 variables\n",
        "\n",
        "Additionally we want to see if we can improve our accuracy"
      ],
      "metadata": {
        "id": "idXJ8wndWkkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are tuning our hyperparameters by searching for the bext n\n",
        "\n",
        "# Define a range of n_estimators to test\n",
        "n_estimators_range = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "\n",
        "# Initialize an empty list to store the mean cross-validation scores\n",
        "cv_scores = []\n",
        "\n",
        "# Perform cross-validation for each value of n_estimators\n",
        "for n in n_estimators_range:\n",
        "    rf_model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    cv_scores.append(np.mean(scores))\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_estimators_range, cv_scores, marker='o')\n",
        "plt.xlabel('Number of Estimators (n_estimators)')\n",
        "plt.ylabel('Cross-Validation Accuracy')\n",
        "plt.title('Cross-Validation Accuracy vs. Number of Estimators')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the n_estimators with the best cross-validation score\n",
        "best_n_estimators = n_estimators_range[np.argmax(cv_scores)]\n",
        "print(f\"Best Number of Estimators: {best_n_estimators}\")\n",
        "\n",
        "# Train the final model with the best number of estimators\n",
        "rf_model = RandomForestClassifier(n_estimators=best_n_estimators, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Set Accuracy: {accuracy}\")\n",
        "\n",
        "# the best n was 350 so plug into code below"
      ],
      "metadata": {
        "id": "lSCecb6sWlqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model= RandomForestClassifier(n_estimators = 350)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "at6j-noHXHlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(\"Accuracy Score: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "feature_df = new_quarter.drop(['churn'], axis = 1)\n",
        "# storing the feature names in a list\n",
        "feature_names_from_dataset = new_quarter.columns.drop('churn').tolist()\n",
        "feature_names_from_dataset\n",
        "\n",
        "# To display feature importances\n",
        "feature_importances = rf_model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "print(feature_importance_df.sort_values(by='Importance', ascending=False))"
      ],
      "metadata": {
        "id": "Q7FtZGPpXLz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf_model.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
        "\n",
        "forest_importances = pd.Series(importances, index = feature_names_from_dataset)\n",
        "# print(forest_importances)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "id": "WCIgBrlgXOXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we're going to take the top 10 most important features in random forest and test for their significance in a logisitic regression"
      ],
      "metadata": {
        "id": "sUYz4jEpXUcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort features by importance\n",
        "sorted_features = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Select the top 10 features\n",
        "top_10_features = sorted_features['Feature'].head(10).tolist()\n",
        "\n",
        "# Add the 'churn' column to the list of features\n",
        "top_10_features.append('churn')\n",
        "\n",
        "# Make a copy of these columns from the original dataset one_two\n",
        "one_two_copy = one_two[top_10_features].copy()\n",
        "\n",
        "# Verify the results\n",
        "print(one_two_copy.head())"
      ],
      "metadata": {
        "id": "egEBwpZ6XRSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so resplit the data\n",
        "\n",
        "selected_rows_churn_0 = one_two_copy[one_two_copy['churn'] == 0].sample(n=16300, random_state=42)\n",
        "\n",
        "# Filter rows where churn is 1\n",
        "rows_churn_1 = one_two_copy[one_two_copy['churn'] == 1]\n",
        "\n",
        "# Concatenate selected_rows_churn_0 with rows_churn_1\n",
        "new_quarter = pd.concat([selected_rows_churn_0, rows_churn_1], ignore_index=True)\n",
        "\n",
        "churn_count = new_quarter['churn'].value_counts()\n",
        "churn_count\n",
        "\n",
        "X = new_quarter.drop('churn', axis=1)\n",
        "y = new_quarter['churn']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FnrjNU19XS_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Logistic Regression classifier\n",
        "logreg_classifier = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(logreg_classifier, X_train, y_train, cv=10)\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lr = logreg_classifier.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "classification_report_result = classification_report(y_test, y_pred_lr)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Logistic Regression Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Logistic Regression Cross-Validation Scores Average:\", np.mean(cv_scores))\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report_result)\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\\n\", confusion_matrix_result)\n",
        "\n",
        "# accuracy of 73%"
      ],
      "metadata": {
        "id": "q9scAkI_Xilr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "# Assuming X_train and y_train are pandas DataFrames\n",
        "X_train = sm.add_constant(X_train)  # Adds an intercept term to the model\n",
        "logit_model = sm.Logit(y_train, X_train)\n",
        "\n",
        "# Fit the model\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Print out the summary of the model\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "zhVLG2P2Xjrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from this second logistic regression, we see that 8/10 variables are statistically significant\n",
        "\n",
        "\n",
        "so for our third analysis, we are going to combine some significant variables from our all-in regression, some important features from our random forest, and a few other variables that are important to look at from a business standpoint"
      ],
      "metadata": {
        "id": "DGgQ_ml4XmdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here we are creating a new dataset wil all variables that we think are important\n",
        "\n",
        "# Drop the 'mobile' column from one_two_copy\n",
        "one_two_copy.drop(columns=['mobile'], inplace=True)\n",
        "\n",
        "# Select the columns to be added from one_two\n",
        "columns_to_add = ['top_ref_campaign', 'ptr', 'd2d', 'promo', 'other_ref_campaign']\n",
        "\n",
        "# Ensure these columns exist in the one_two DataFrame\n",
        "for column in columns_to_add:\n",
        "    if column not in one_two.columns:\n",
        "        raise ValueError(f\"Column '{column}' does not exist in the one_two DataFrame\")\n",
        "\n",
        "# Add these columns to one_two_copy\n",
        "one_two_copy = one_two_copy.join(one_two[columns_to_add])\n",
        "\n",
        "# Verify the results\n",
        "print(one_two_copy.head())"
      ],
      "metadata": {
        "id": "t3T-pFkUXk-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# respliting the data\n",
        "\n",
        "selected_rows_churn_0 = one_two_copy[one_two_copy['churn'] == 0].sample(n=16300, random_state=42)\n",
        "\n",
        "# Filter rows where churn is 1\n",
        "rows_churn_1 = one_two_copy[one_two_copy['churn'] == 1]\n",
        "\n",
        "# Concatenate selected_rows_churn_0 with rows_churn_1\n",
        "new_quarter = pd.concat([selected_rows_churn_0, rows_churn_1], ignore_index=True)\n",
        "\n",
        "churn_count = new_quarter['churn'].value_counts()\n",
        "churn_count\n",
        "\n",
        "X = new_quarter.drop('churn', axis=1)\n",
        "y = new_quarter['churn']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ToeCneyYX4gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Logistic Regression classifier\n",
        "logreg_classifier = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(logreg_classifier, X_train, y_train, cv=10)\n",
        "\n",
        "# Train the model on the training set\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lr = logreg_classifier.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "classification_report_result = classification_report(y_test, y_pred_lr)\n",
        "confusion_matrix_result = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Logistic Regression Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Logistic Regression Cross-Validation Scores Average:\", np.mean(cv_scores))\n",
        "print(\"Logistic Regression Accuracy:\", accuracy)\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report_result)\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\\n\", confusion_matrix_result)\n",
        "\n",
        "\n",
        "# accuracy of 73%"
      ],
      "metadata": {
        "id": "0xtiEz9mYCPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "# Assuming X_train and y_train are pandas DataFrames\n",
        "X_train = sm.add_constant(X_train)  # Adds an intercept term to the model\n",
        "logit_model = sm.Logit(y_train, X_train)\n",
        "\n",
        "# Fit the model\n",
        "result = logit_model.fit()\n",
        "\n",
        "# Print out the summary of the model\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "qzHZXwibYJcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# because this is a logisitic regression, we are now calculating the\n",
        "# probabilities so we can better interpret the results\n",
        "\n",
        "# Extract coefficients\n",
        "coefficients = result.params\n",
        "odds_ratios = np.exp(coefficients)\n",
        "\n",
        "# Create a DataFrame for easy interpretation\n",
        "interpretation_df = pd.DataFrame({\n",
        "    'Feature': coefficients.index,\n",
        "    'Coefficient (Log Odds)': coefficients.values,\n",
        "    'Odds Ratio': odds_ratios\n",
        "})\n",
        "\n",
        "print(interpretation_df)"
      ],
      "metadata": {
        "id": "84eVR_euYMH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our final model achieves an accuracy of 73%, comparable to our initial two models. It stands out for its simplicity and ease of interpretation, making it more accessible for businesses. Additionally, the model incorporates relevant variables that can offer valuable insights into areas where the company can improve."
      ],
      "metadata": {
        "id": "DhA45CTqYa7H"
      }
    }
  ]
}